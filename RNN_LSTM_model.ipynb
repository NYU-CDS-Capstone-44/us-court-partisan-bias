{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c84e248-a2fc-488c-9ece-c9f7d49d9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Collecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (2022.1.0)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /ext3/miniconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed filelock-3.13.1 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.1.0 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f8ecfa-dcec-407b-9bdf-fc232a123fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.16.0-cp39-cp39-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.9/site-packages (from torchtext) (4.62.3)\n",
      "Requirement already satisfied: torch==2.1.0 in /home/amr10211/.local/lib/python3.9/site-packages (from torchtext) (2.1.0)\n",
      "Collecting torchdata==0.7.0\n",
      "  Downloading torchdata-0.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /ext3/miniconda3/lib/python3.9/site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: numpy in /ext3/miniconda3/lib/python3.9/site-packages (from torchtext) (1.22.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (3.0.3)\n",
      "Requirement already satisfied: sympy in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (8.9.2.26)\n",
      "Requirement already satisfied: filelock in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /ext3/miniconda3/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (2022.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions in /ext3/miniconda3/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (4.0.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/amr10211/.local/lib/python3.9/site-packages (from torch==2.1.0->torchtext) (12.1.0.106)\n",
      "Requirement already satisfied: urllib3>=1.25 in /ext3/miniconda3/lib/python3.9/site-packages (from torchdata==0.7.0->torchtext) (1.26.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/amr10211/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext) (12.3.52)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->torchtext) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from jinja2->torch==2.1.0->torchtext) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/amr10211/.local/lib/python3.9/site-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
      "Installing collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.7.0 torchtext-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad661bf-ffd1-4e75-aa1d-ade1b31bf0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/amr10211/.local/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (60.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /ext3/miniconda3/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/amr10211/.local/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /ext3/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/amr10211/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/amr10211/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/amr10211/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/amr10211/.local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/amr10211/.local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /ext3/miniconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/amr10211/.local/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b40fe18e-5315-41af-b409-0a891b9c51bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /home/amr10211/.local/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /ext3/miniconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/amr10211/.local/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/amr10211/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /ext3/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.11)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.10.0 huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb2cb3d9-ad8e-4f72-83b4-d7625548c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /ext3/miniconda3/lib/python3.9/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /ext3/miniconda3/lib/python3.9/site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/amr10211/.local/lib/python3.9/site-packages (from gensim) (6.4.0)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43a82b8a-51d5-4291-b311-981802b7eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.5\n",
      "  Downloading numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /ext3/miniconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.9/site-packages (from tensorflow) (60.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/amr10211/.local/lib/python3.9/site-packages (from tensorflow) (4.8.0)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m47.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.0-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.4/294.4 KB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /ext3/miniconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /ext3/miniconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m449.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /ext3/miniconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /ext3/miniconda3/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.27.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 KB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /ext3/miniconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.7)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /ext3/miniconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow) (4.11.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /ext3/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.8)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /ext3/miniconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, ml-dtypes, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The script f2py is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown_py is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/amr10211/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.8.0 requires numpy<1.25.0,>=1.17.3, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.2 keras-2.14.0 libclang-16.0.6 markdown-3.5.1 ml-dtypes-0.2.0 numpy-1.26.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 werkzeug-3.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7e9376c-5943-4538-bed8-115a29447da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras.preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /ext3/miniconda3/lib/python3.9/site-packages (from keras.preprocessing) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/amr10211/.local/lib/python3.9/site-packages (from keras.preprocessing) (1.26.1)\n",
      "Installing collected packages: keras.preprocessing\n",
      "Successfully installed keras.preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b71beab9-e958-4ed0-80e2-91e9e78f73e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/amr10211/.local/lib/python3.9/site-packages (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9ba648-0e9f-4647-9c6f-5d251ed025b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to /home/amr10211/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from transformers import AutoTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "# import tensorflow\n",
    "# from tensorflow import pad_sequences\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings as wrn\n",
    "wrn.filterwarnings('ignore')\n",
    "\n",
    "SEED = 7\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cuda.deterministic = True\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06171245-2f61-4d2e-9001-2117c0d3ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/vast/amr10211/sc-train.csv')\n",
    "val = pd.read_csv('/vast/amr10211/sc-val.csv')\n",
    "test = pd.read_csv('/vast/amr10211/sc-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d66d1fd-6e7d-46dd-a85b-8bcbe10de08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word2Vec_embeddings(corpus, model_file_path):\n",
    "    # Tokenize the sentences\n",
    "    tokenized_corpus = [word_tokenize(doc.lower()) for doc in corpus]\n",
    "\n",
    "    # Train Word2Vec model\n",
    "    model = Word2Vec(sentences=tokenized_corpus, vector_size=50, window=5, sg=1, min_count=1)\n",
    "    \n",
    "    #Save model\n",
    "    model.save(model_file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827f10e6-3254-49e7-9132-33ec3b9c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat all text for Word2Vec model\n",
    "all_text = list(train['decision_text'])+list(val['decision_text'])+list(test['decision_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce176d9-d507-4ebe-b20f-3a0fd8bc5bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d4a140253c477395296d23f175a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train Word2Vec model\n",
    "w2v_model = Word2Vec_embeddings(tqdm(all_text),\"w2v_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f4bd61-4519-4516-8849-3baa0f6dd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Word2Vec modl\n",
    "w2v_model = Word2Vec.load(\"w2v_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13e7213b-3efd-4cde-81d6-6a932ea23bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar: [('wartime', 0.8486567139625549), ('hostilities', 0.840330958366394), ('war.', 0.8261163830757141), ('1812.', 0.8198104500770569), ('internment', 0.8171284198760986)]\n"
     ]
    }
   ],
   "source": [
    "# # Get the vector for a specific word\n",
    "# vector = w2v_model.wv['america']\n",
    "# print(f\"Vector: {vector}\")\n",
    "\n",
    "# # Find similar words\n",
    "# similar_words = w2v_model.wv.most_similar('war', topn=5)\n",
    "# print(f\"Words similar: {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f2c5e10-8681-43a9-b47a-8df216472f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_vectorize_pad(data, model):\n",
    "    # Tokenize the documents\n",
    "    tokenized_data = [word_tokenize(doc.lower()) for doc in data]\n",
    "\n",
    "    # Assuming 'model' is your Word2Vec model\n",
    "    vector_size = model.vector_size  # Get the size of the word vectors\n",
    "\n",
    "    # Convert tokens to word vectors\n",
    "    word_vectors = [[model.wv[token] for token in doc if token in model.wv] for doc in tokenized_data]\n",
    "\n",
    "    # Find the maximum length\n",
    "    max_length = max(len(doc) for doc in word_vectors)\n",
    "\n",
    "    # Pad or truncate each document to the maximum length using NumPy\n",
    "    padded_sequences = np.array([doc + [np.zeros(vector_size)] * (max_length - len(doc)) for doc in word_vectors])\n",
    "\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1926438-29c7-4fa5-8b2a-3a7eda6ae3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenize_vectorize_pad(tqdm(train['decision_text']), w2v_model)\n",
    "X_val = tokenize_vectorize_pad(tqdm(val['decision_text']), w2v_model)\n",
    "X_test = tokenize_vectorize_pad(tqdm(test['decision_text']), w2v_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c819dd96-b4f9-4f19-b0ca-d2266c8f1e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.07574825, -0.09674057, -0.00457904, ...,  0.42638454,\n",
       "          0.48977536,  0.03370301],\n",
       "        [-0.28768653, -0.27136409, -0.57421142, ..., -0.23679963,\n",
       "          0.50534672,  0.04510672],\n",
       "        [-0.1061649 , -0.4855656 ,  0.17736124, ..., -0.45044851,\n",
       "          0.619789  ,  0.05577757],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.07574825, -0.09674057, -0.00457904, ...,  0.42638454,\n",
       "          0.48977536,  0.03370301],\n",
       "        [-0.28768653, -0.27136409, -0.57421142, ..., -0.23679963,\n",
       "          0.50534672,  0.04510672],\n",
       "        [-0.65883952, -0.49549466, -0.77076483, ...,  0.42512158,\n",
       "          0.59283501,  0.04423743],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.07574825, -0.09674057, -0.00457904, ...,  0.42638454,\n",
       "          0.48977536,  0.03370301],\n",
       "        [-0.28768653, -0.27136409, -0.57421142, ..., -0.23679963,\n",
       "          0.50534672,  0.04510672],\n",
       "        [-0.32596195, -0.99388999, -0.15397011, ...,  0.26999599,\n",
       "         -0.07736742,  0.66774309],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.28768653, -0.27136409, -0.57421142, ..., -0.23679963,\n",
       "          0.50534672,  0.04510672],\n",
       "        [-0.13445967,  0.20862049, -0.97027582, ..., -0.1101979 ,\n",
       "          0.68438488, -0.07834914],\n",
       "        [ 0.36971429, -0.41599539,  0.05005679, ...,  0.26015034,\n",
       "          0.84682381, -0.2499491 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.28768653, -0.27136409, -0.57421142, ..., -0.23679963,\n",
       "          0.50534672,  0.04510672],\n",
       "        [-0.29677543,  0.03505477, -0.78417695, ..., -0.03587007,\n",
       "          0.43635729,  0.04976319],\n",
       "        [ 0.2815043 , -0.28559485, -0.13124274, ..., -0.35226151,\n",
       "          0.13320217,  0.67434233],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.12362339, -0.57878584,  0.17794678, ..., -0.10628887,\n",
       "          0.41675177,  0.70748895],\n",
       "        [ 0.01894412,  0.08186001,  0.01182625, ..., -0.0633369 ,\n",
       "          0.13770533,  0.06729421],\n",
       "        [-0.13445967,  0.20862049, -0.97027582, ..., -0.1101979 ,\n",
       "          0.68438488, -0.07834914],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bacf9-d3fb-4a51-b450-7227ec6cb127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715ed64-fc70-4029-ba76-98af23b80021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b4bbf-c867-4c00-b1eb-3b86ea688478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a9d56-7b98-48e7-b966-e5ac7ba72eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ac84ef0-1171-468c-8472-54c3b42dbb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2508,  119,  ..., 3081,  119,  102]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_encoding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccd9c8ba-89b5-4217-a55a-38a7104f882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0883b15e75445d58dea97f118317546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336aec8819ee439ebe2c88ed4886836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39c0f35e31d4b2683f8a6f607d5f5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize decision text\n",
    "def tokenize_data(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "train['decision_text_tokens'] = train['decision_text'].progress_apply(tokenize_data)\n",
    "val['decision_text_tokens'] = val['decision_text'].progress_apply(tokenize_data)\n",
    "test['decision_text_tokens'] = test['decision_text'].progress_apply(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa2e4bd5-01db-41dd-ac3e-375aac8de267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['decision_text_tokens']\n",
    "X_val = val['decision_text_tokens']\n",
    "X_test = test['decision_text_tokens']\n",
    "\n",
    "y_train = train['scdb_decision_direction']\n",
    "y_val = val['scdb_decision_direction']\n",
    "y_test = test['scdb_decision_direction']\n",
    "\n",
    "# Combo of train and val:\n",
    "X = pd.concat([X_train, X_val], axis=0) \n",
    "y = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "#Dictionary versions of train and val\n",
    "train_data = pd.concat([y_train,X_train],axis=1).to_dict(orient='records')\n",
    "val_data = pd.concat([y_val,X_val],axis=1).to_dict(orient='records')\n",
    "\n",
    "#Batch\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d790370-95f0-4397-a218-1c94613e1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(X):\n",
    "    print(\"Building Vocabulary ...\")\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        X,\n",
    "        min_freq=1,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    # Default index to return when OOV (out of vocab)\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc49b793-f24d-409c-a088-3a39573759da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(X):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab = build_vocabulary(X)\n",
    "        torch.save((vocab), \"vocab.pt\")\n",
    "    else:\n",
    "        vocab = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(len(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "215d1c26-a35d-40cc-8ee3-802699ee2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n",
      "563250\n"
     ]
    }
   ],
   "source": [
    "vocab = load_vocab(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2719ceb3-0646-45a3-bd0f-761e509431df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 103443\n"
     ]
    }
   ],
   "source": [
    "max_length = len(max(X, key=len))\n",
    "print('Max Sequence Length:',max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89f11a04-c495-4d18-85a7-23604e432a3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'Iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Batch data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 4\u001b[0m train_iterator,validation_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIterator\u001b[49m(\n\u001b[1;32m      5\u001b[0m     (train_data,valid_data),\n\u001b[1;32m      6\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m BATCH_SIZE,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Sort key is how to sort the samples\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     sort_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mtext),\n\u001b[1;32m      9\u001b[0m     sort_within_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     device \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Iterator'"
     ]
    }
   ],
   "source": [
    "# #Batch data\n",
    "# BATCH_SIZE = 1000\n",
    "\n",
    "# train_iterator,validation_iterator = torchtext.data.Iterator(\n",
    "#     (train_data,valid_data),\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     # Sort key is how to sort the samples\n",
    "#     sort_key = lambda x:len(x.text),\n",
    "#     sort_within_batch = True,\n",
    "#     device = device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "973d2607-580d-4021-afa3-008e8ea451c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMBinaryClassifier(\n",
      "  (lstm): LSTM(103443, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer with sigmoid activation for binary classification\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,forx):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out.squeeze(1)  # Squeeze the output to make it compatible with binary cross-entropy loss\n",
    "\n",
    "# Example usage\n",
    "input_size = max_length  # Assuming each word is represented as a 300-dimensional vector\n",
    "hidden_size = 64  # Number of hidden units in the LSTM\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "\n",
    "# Create an instance of the LSTM binary classifier model\n",
    "model = LSTMBinaryClassifier(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b57a4d4-2262-4505-9dfe-cbb79ae8c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f479162-f04e-467f-ada9-e7ffa10d92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,iterator,optimizer,criterion):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    \n",
    "    # model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        # cleaning the cache of optimizer\n",
    "        optimizer.zero_grad()\n",
    "        print(batch)\n",
    "        text = [d['decision_text_tokens'] for d in batch]\n",
    "        text_lengths = [len(value) for value in text]\n",
    "        \n",
    "        # text,text_lengths = batch.text\n",
    "                  \n",
    "        # Sort the batch by text length in descending order\n",
    "        text_lengths, sort_indices = text_lengths.sort(descending=True)\n",
    "        text = text[:, sort_indices]\n",
    "        \n",
    "        # Pack the padded sequences\n",
    "        packed_text = rnn_utils.pack_padded_sequence(text, text_lengths)\n",
    "        \n",
    "        print(packed_text)\n",
    "        # Forward propagation and squeezing\n",
    "        predictions = model(packed_text)  \n",
    "        \n",
    "        \n",
    "        # computing loss / backward propagation\n",
    "        loss = criterion(predictions,batch.type)\n",
    "        loss.backward()\n",
    "        \n",
    "        # accuracy\n",
    "        acc = binary_accuracy(predictions,batch.type)\n",
    "        \n",
    "        # updating params\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    # It'll return the means of loss and accuracy\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59fe24e8-4208-412a-a28d-f5101e6ccc08",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      4\u001b[0m epoch_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model.train()\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# cleaning the cache of optimizer\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:138\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    136\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "train_model(model,train_dataloader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e62209b-f680-4261-9142-ab67071569dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>decision_text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[*, 18, MR., Justice, Black, delivered, the, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[*, 58Mr, ., Justice, Frankfurter, delivered, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[Mr., Justice, Roberts, ,, dissenting, :, I, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[*, 109, Mr., Justice, Murphy, delivered, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[Mr., Justice, Reed, delivered, the, opinion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[397, U.S., 397, (, 1970, ), ROSADO, ET, AL, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[520, U.S., 681, (, 1997, ), CLINTON, v., JONE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[Per, Curiam, ., The, Emergency, Medical, Trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[356, U.S., 274, (, 1958, ), FIDELITY-PHILADEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[*, 217, Per, Curiam, ., I, Congress, has, ado...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21107 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scdb_decision_direction  \\\n",
       "0                         2.0   \n",
       "1                         2.0   \n",
       "2                         1.0   \n",
       "3                         2.0   \n",
       "4                         1.0   \n",
       "...                       ...   \n",
       "5317                      2.0   \n",
       "5318                      1.0   \n",
       "5319                      2.0   \n",
       "5320                      1.0   \n",
       "5321                      2.0   \n",
       "\n",
       "                                   decision_text_tokens  \n",
       "0     [*, 18, MR., Justice, Black, delivered, the, o...  \n",
       "1     [*, 58Mr, ., Justice, Frankfurter, delivered, ...  \n",
       "2     [Mr., Justice, Roberts, ,, dissenting, :, I, a...  \n",
       "3     [*, 109, Mr., Justice, Murphy, delivered, the,...  \n",
       "4     [Mr., Justice, Reed, delivered, the, opinion, ...  \n",
       "...                                                 ...  \n",
       "5317  [397, U.S., 397, (, 1970, ), ROSADO, ET, AL, ....  \n",
       "5318  [520, U.S., 681, (, 1997, ), CLINTON, v., JONE...  \n",
       "5319  [Per, Curiam, ., The, Emergency, Medical, Trea...  \n",
       "5320  [356, U.S., 274, (, 1958, ), FIDELITY-PHILADEL...  \n",
       "5321  [*, 217, Per, Curiam, ., I, Congress, has, ado...  \n",
       "\n",
       "[21107 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_input = pd.concat([y,X],axis=1).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8569262-b259-4da8-8785-a7f345114678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771be41-1ab2-4fad-9c9c-e79827b8880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c68c10-be35-480d-95f5-50e1ecd1ea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07778034-7517-453a-a70c-a555c3b71e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "\n",
    "    step: int = 0  # Steps in the current epoch\n",
    "    accum_step: int = 0  # Number of gradient accumulation steps\n",
    "    samples: int = 0  # total number of examples used\n",
    "    tokens: int = 0  # total number of tokens processed\n",
    "    \n",
    "    \n",
    "def run_epoch(\n",
    "    data_iter,\n",
    "    model,\n",
    "    loss_compute,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mode=\"train\",\n",
    "    accum_iter=1,\n",
    "    train_state=TrainState(),\n",
    "):\n",
    "    \"\"\"Train a single epoch\"\"\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    n_accum = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        \n",
    "        # Forward Pass\n",
    "        out = model.forward(\n",
    "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
    "        )\n",
    "        \n",
    "        # Compute loss\n",
    "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            # Backward pass\n",
    "            loss_node.backward()\n",
    "            train_state.step += 1\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            train_state.tokens += batch.ntokens\n",
    "            \n",
    "            # Apply optimizer step every accum_iter iterations\n",
    "            if i % accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                n_accum += 1\n",
    "                train_state.accum_step += 1\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 40 == 1 and (mode == \"train\"):\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                (\n",
    "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
    "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
    "                )\n",
    "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
    "            )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
